{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import pyaudio\n",
    "import wave \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, Write, Show Videos from Camera in OpenCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n",
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)#open your laptop camera\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') #use any fourcc type to improve quality for the saved video\n",
    "out = cv2.VideoWriter('videos/output.avi', fourcc, 20.0, (640,480)) #Video settings\n",
    "\n",
    "\n",
    "print(cap.isOpened()) #check if the camera is opened\n",
    "while(cap.isOpened()): #while loop to read all frames\n",
    "    ret, frame = cap.read() #read all frams if ret is TRUE it means that there is a frames to process   \n",
    "    if ret == True: #if ret is true   \n",
    "       print(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #get the frame width       \n",
    "       print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) #get the frame height       \n",
    "\n",
    "       out.write(frame) #save your video       \n",
    "\n",
    "       #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert frames from BGR2GRAY       \n",
    "       #cv2.imshow('Frame Name ...', gray) #show the frames    \n",
    "\n",
    "       cv2.imshow('Frame Name ...', frame) #show the frames       \n",
    "\n",
    "       if cv2.waitKey(1) & 0xFF == ord('q'): #if u pressed q close the window and break       \n",
    "         break          \n",
    "    else: #it will enter here if the ret = false and break the code  \n",
    "        break     \n",
    "\n",
    "cap.release() #close the camera after u finish the running process\n",
    "out.release() #release your video after u save it\n",
    "cv2.destroyAllWindows() #close any opened window\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To show an existing video file in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('videos/output.avi')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "# Loop through all the frames in the video\n",
    "while True:\n",
    "    ret, frame = cap.read() # read the next frame\n",
    "    if ret: # if the frame was read successfully\n",
    "        cv2.imshow('Frame Name', frame) # show the frame in a window named 'Frame Name'\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'): # wait for a key press, and break the loop if 'q' is pressed\n",
    "            break\n",
    "    else: # if there are no more frames to read, break the loop\n",
    "        break\n",
    "\n",
    "# Release the video file and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To capture sound along with the video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set up the audio recording\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)\n",
    "frames = []\n",
    "\n",
    "# Set up the video recording\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('videos/output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Loop through each frame\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the video frame to file\n",
    "        out.write(frame)\n",
    "\n",
    "        # Record the audio\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the audio\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "wf = wave.open('videos/output_with_sound.wav', 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "wf.setframerate(44100)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use  phone camera (app IPWEBCAM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Replace the URL with your own IP webcam URL\n",
    "url = 'http://100.82.229.74:8080/video'\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open IP webcam\")\n",
    "    exit()\n",
    "\n",
    "# Read and display frames from the webcam\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow('IP Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Date and Time on Video using OpenCVm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera in opened\n",
      "Width : 640.0\n",
      "Height : 480.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)#open your laptop camera\n",
    "\n",
    "if cap.isOpened() : #check if the camera is opened\n",
    "   print(\"Camera in opened\")\n",
    "\n",
    "  #  cap.set(3, cv2.CAP_PROP_FRAME_WIDTH) # this will be the max width  of the camera\n",
    "  #  cap.set(4, cv2.CAP_PROP_FRAME_HEIGHT) # this will be the max heigth  of the camera\n",
    "   \n",
    "   cap.set(3, 3000) # now we control width and height\n",
    "   cap.set(3, 3000)\n",
    "\n",
    "   Width = cap.get(3)\n",
    "   Height = cap.get(4)\n",
    "   print(f\"Width : {Width}\")\n",
    "   print(f\"Height : {Height}\")\n",
    "\n",
    "\n",
    "while(cap.isOpened()): #while loop to read all frames\n",
    "    ret, frame = cap.read() #read all frams if ret is TRUE it means that there is a frames to process   \n",
    "    if ret == True: #if ret is true    \n",
    "       \n",
    "       font = cv2.FONT_HERSHEY_COMPLEX_SMALL             \n",
    "       text = 'Width: '+ str(cap.get(3)) + ' Height:' + str(cap.get(4))             \n",
    "       datet = str(datetime.datetime.now())             \n",
    "       frame = cv2.putText(frame, text, (10, int(Height-50)), font, 1, (0, 255, 255), 1)              \n",
    "       frame = cv2.putText(frame, datet, (10, int(Height-10)), font, 1, (0, 255, 255), 1)\n",
    "\n",
    "       cv2.imshow('Frame Name ...', frame) #show the frames       \n",
    "\n",
    "       if cv2.waitKey(1) & 0xFF == ord('q'): #if you pressed q close the window and break       \n",
    "         break          \n",
    "    else: #it will enter here if the ret = false and break the code  \n",
    "        break     \n",
    "\n",
    "cap.release() #close the camera after u finish the running process\n",
    "cv2.destroyAllWindows() #close any opened window\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](videos/test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection and Object Tracking Using HSV Color Space\n",
    "- H : Hue represents the actual color of the pixel, expressed in degrees from 0 to 360 around a color wheel. Red is at 0 degrees, green is at 120 degrees, and blue is at 240 degrees.\n",
    "\n",
    "- S : Saturation represents the purity of the color, with 0% saturation being grayscale and 100% saturation being fully saturated.\n",
    "\n",
    "- V : Value represents the brightness or intensity of the color, with 0% value being black and 100% value being the maximum brightness of the color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/apprenant/miniconda3/envs/CV/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "# url = 'http://100.82.229.74:8080/video'\n",
    "# cap = cv2.VideoCapture(url)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"Lower H\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower S\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower V\", \"Tracking\", 0, 255, nothing)\n",
    "\n",
    "cv2.createTrackbar(\"Upper H\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper S\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper V\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)       \n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"Lower H\", \"Tracking\")       \n",
    "    l_s = cv2.getTrackbarPos(\"Lower S\", \"Tracking\")       \n",
    "    l_v = cv2.getTrackbarPos(\"Lower V\", \"Tracking\") \n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper H\", \"Tracking\")       \n",
    "    u_s = cv2.getTrackbarPos(\"Upper S\", \"Tracking\")       \n",
    "    u_v = cv2.getTrackbarPos(\"Upper V\", \"Tracking\")    \n",
    "\n",
    "    l_array = np.array([l_h, l_s, l_v])       \n",
    "    u_array = np.array([u_h, u_s, u_v])       \n",
    "\n",
    "    mask = cv2.inRange(hsv, l_array, u_array)       \n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)        \n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)        \n",
    "    cv2.imshow(\"mask\", mask)        \n",
    "    cv2.imshow(\"res\", res)        \n",
    "\n",
    "    key = cv2.waitKey(1)         \n",
    "\n",
    "    if key == 27:        \n",
    "\n",
    "        break               \n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() #colse window\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](videos/blue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
